# Requirements: Python, nltk, nltk data, NumPy, Matplotlib
# pip install nltk

import nltk
from __future__ import division

# Get corpora
nltk.download()

## Textsuche
# Concordance: Anzahl Vorkommnisse mit Vor- und Nachtext gelistet
<text>.concordance("<token>")

# Similarity: Auflistung in ähnlichem Kontext genutzer Begriffe
<text>.similar("<token>")

# Common Context: Auflistung von Begriffen mit gleichem Kontext
<text>.common_contexts(["token_1", "token_n"])

# Dispersion Plot: Vorkommnisse mit Textpositionen visualisiert
<text>.dispersion_plot(["token_1", "token_n"])

## Zählen von Wörtern
# Anzahl Wörter
len(<text>)

# Liste aller unterschiedlichen Token (Wörter, Satzzeichen etc.)
sorted(set(<text>))

# Anzahl unterschiedlicher Token
len(set(<text>))

# Anzahl Vorkommen eines Tokens
<text>.count("<token>")

# Lexical diversity: Verhältnis unterschiedlicher Wörter zu Anzahl aller Wörter
len(set(<text>)) / len(<text>)

## Simple Statistiken
# Frequency Distributions: Ausgabe der Vorkommnisse von Token
# http://www.nltk.org/_modules/nltk/probability.html
fdist = FreqDist(<text>)

fdist.freq("<text>")
fdist.max()
fdist.N()

# Most common
fdist.most_common(50)

# Visualisierung
fdist.plot(50, cumulative=True)

# Lange Wörter
long_words = [w for w in set(<text>) if len(w) > <count>]

# Collocation: Zusammenhängende Begriffe aus min. 2 Wörtern
<text>.collocations()

# Hapax: Ein Mal vorkommende Wörter im gesamten Text
fdist.hapaxes()

## Erweiterter Zugriff auf Corpora
# Conditional Frequency Distributions
from nltk.corpus import brown
cfd = nltk.ConditionalFreqDist(
    (genre, word)
    for genre in brown.categories()
    for word in brown.words(categories=genre))

# Hilfe
help(nltk.corpus.reader)

## Eigene Corpora erstellen
# Aus Txt
file = open(r'C:\Users\sko\Documents\FOM\Thesis\sentiment.txt', 'rU')
raw = file.read()
txt = nltk.Text(nltk.word_tokenize(raw))
fdist = FreqDist(txt)

# PlaintextCorpusReader
from nltk.corpus import PlaintextCorpusReader
corpus_root = r'C:\Users\sko\Documents\FOM\Thesis'
wordlists = PlaintextCorpusReader(corpus_root, '.txt')
wordlists.fileids()
wordlists.words('<text>')

# BracketParseCorpusReader für FilePatterns
from nltk.corpus import BracketParseCorpusReader
corpus_root = r'C:\Users\sko\Documents\FOM\Thesis'
file_pattern = r".*\.txt" [2]
ptb = BracketParseCorpusReader(corpus_root, file_pattern)
ptb.fileids()
len(ptb.sents())
ptb.sents(fileids='<file.txt>')
